{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20155,"status":"ok","timestamp":1675141033018,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"},"user_tz":-540},"id":"ivO-xJvVo27_","outputId":"c4756894-0418-406e-de6c-0ff8bf50ba4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1675141036155,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"},"user_tz":-540},"id":"kMgqcPHtvCiv","outputId":"b72af622-1a00-4c80-874c-a8561b5b0d48"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Google Colab\n"]}],"source":["#カレントディレクトリに移動\n","%cd \"/content/drive/My Drive/Google Colab\""]},{"cell_type":"markdown","source":["# 以下没コード！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！"],"metadata":{"id":"HpXTYt9fc9Zk"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45408,"status":"ok","timestamp":1675141107405,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"},"user_tz":-540},"id":"bB9zE-zDvaLi","outputId":"bee979bc-6f22-4957-8c9a-fa5c061cba28"},"outputs":[{"output_type":"stream","name":"stdout","text":["open_image/03/m_204_03.png\n","open_image/03/m_205_03.png\n","open_image/03/m_220_03.png\n","open_image/03/m_221_03.png\n","open_image/03/m_237_03.png\n","open_image/03/m_238_03.png\n","open_image/03/m_256_03.png\n","open_image/03/m_257_03.png\n","open_image/03/m_258_03.png\n","open_image/03/m_259_03.png\n","open_image/03/m_279_03.png\n","open_image/03/m_280_03.png\n","open_image/03/m_295_03.png\n","open_image/03/m_296_03.png\n","open_image/03/m_297_03.png\n","open_image/03/03-01-01-01-01-01-04.png\n","open_image/03/03-01-03-01-01-02-04.png\n","open_image/03/03-01-03-02-02-01-04.png\n","open_image/03/03-01-03-01-01-01-04.png\n","open_image/03/03-01-03-02-02-02-04.png\n","open_image/03/03-01-03-02-01-01-04.png\n","open_image/03/03-01-03-02-01-02-04.png\n","open_image/03/03-01-03-01-02-01-04.png\n","open_image/03/03-01-03-01-02-02-04.png\n","open_image/03/03-01-01-01-01-01-05.png\n","open_image/03/03-01-03-01-01-02-05.png\n","open_image/03/03-01-03-01-02-02-05.png\n","open_image/03/03-01-03-01-02-01-05.png\n","open_image/03/03-01-03-01-01-01-05.png\n","open_image/03/03-01-03-02-01-01-05.png\n","open_image/03/03-01-03-02-01-02-05.png\n","open_image/03/03-01-03-02-02-01-05.png\n","open_image/03/03-01-03-02-02-02-05.png\n","open_image/03/03-01-03-01-02-01-06.png\n","open_image/03/03-01-03-01-01-01-06.png\n","open_image/03/03-01-03-01-02-02-06.png\n","open_image/03/03-01-03-01-01-02-06.png\n","open_image/03/03-01-03-02-02-01-06.png\n","open_image/03/03-01-03-02-01-01-06.png\n","open_image/03/03-01-03-02-02-02-06.png\n","open_image/03/03-01-03-02-01-02-06.png\n","open_image/03/03-01-03-02-01-02-07.png\n","open_image/03/03-01-03-01-02-02-07.png\n","open_image/03/03-01-03-02-02-02-07.png\n","open_image/03/03-01-03-01-02-01-07.png\n","open_image/03/03-01-03-02-02-01-07.png\n","open_image/03/03-01-03-01-01-01-07.png\n","open_image/03/03-01-03-01-01-02-07.png\n","open_image/03/03-01-03-02-01-01-07.png\n","open_image/03/03-01-03-01-02-01-08.png\n","open_image/03/03-01-03-01-01-01-08.png\n","open_image/03/03-01-03-02-02-02-08.png\n","open_image/03/03-01-03-02-02-01-08.png\n","open_image/03/03-01-03-02-01-02-08.png\n","open_image/03/03-01-03-01-02-02-08.png\n","open_image/03/03-01-03-01-01-02-08.png\n","open_image/03/03-01-03-02-01-01-08.png\n","open_image/03/03-01-03-01-02-01-09.png\n","open_image/03/03-01-03-01-01-01-09.png\n","open_image/03/03-01-03-01-01-02-09.png\n","open_image/03/03-01-03-02-01-01-09.png\n","open_image/03/03-01-03-02-02-01-09.png\n","open_image/03/03-01-03-02-02-02-09.png\n","open_image/03/03-01-03-01-02-02-09.png\n","open_image/03/03-01-03-02-01-02-09.png\n","open_image/03/03-01-03-01-01-01-10.png\n","open_image/03/03-01-03-01-01-02-10.png\n","open_image/03/03-01-03-01-02-01-10.png\n","open_image/03/03-01-03-02-01-02-10.png\n","open_image/03/03-01-03-02-02-02-10.png\n","open_image/03/03-01-03-02-02-01-10.png\n","open_image/03/03-01-03-01-02-02-10.png\n","open_image/03/03-01-03-02-01-01-10.png\n","open_image/03/03-01-03-02-02-01-11.png\n","open_image/03/03-01-03-02-01-01-11.png\n","open_image/03/03-01-03-01-02-01-11.png\n","open_image/03/03-01-03-01-02-02-11.png\n","open_image/03/03-01-03-01-01-02-11.png\n","open_image/03/03-01-03-02-02-02-11.png\n","open_image/03/03-01-03-02-01-02-11.png\n","open_image/03/03-01-03-01-01-01-11.png\n","open_image/03/03-01-03-01-01-02-12.png\n","open_image/03/03-01-03-01-01-01-12.png\n","open_image/03/03-01-03-02-02-01-12.png\n","open_image/03/03-01-03-01-02-01-12.png\n","open_image/03/03-01-03-02-01-02-12.png\n","open_image/03/03-01-03-02-01-01-12.png\n","open_image/03/03-01-03-01-02-02-12.png\n","open_image/03/03-01-03-02-02-02-12.png\n","open_image/03/03-01-03-02-02-01-13.png\n","open_image/03/03-01-03-01-01-02-13.png\n","open_image/03/03-01-03-02-01-01-13.png\n","open_image/03/03-01-03-01-02-01-13.png\n","open_image/03/03-01-03-01-02-02-13.png\n","open_image/03/03-01-03-01-01-01-13.png\n","open_image/03/03-01-03-02-01-02-13.png\n","open_image/03/03-01-03-02-02-02-13.png\n","open_image/03/03-01-03-02-02-02-14.png\n","open_image/03/03-01-03-01-01-02-14.png\n","open_image/03/03-01-03-01-02-01-14.png\n","open_image/03/03-01-03-02-02-01-14.png\n","open_image/03/03-01-03-02-01-02-14.png\n","open_image/03/03-01-03-02-01-01-14.png\n","open_image/03/03-01-03-01-01-01-14.png\n","open_image/03/03-01-03-01-02-02-14.png\n","open_image/03/03-01-02-02-02-02-15.png\n","open_image/02/m_206_02.png\n","open_image/02/m_207_02.png\n","open_image/02/m_222_02.png\n","open_image/02/m_223_02.png\n","open_image/02/m_239_02.png\n","open_image/02/m_240_02.png\n","open_image/02/m_260_02.png\n","open_image/02/m_261_02.png\n","open_image/02/m_262_02.png\n","open_image/02/m_281_02.png\n","open_image/02/m_282_02.png\n","open_image/02/m_298_02.png\n","open_image/02/m_299_02.png\n","open_image/04/m_212_04.png\n","open_image/04/m_213_04.png\n","open_image/04/m_228_04.png\n","open_image/04/m_229_04.png\n","open_image/04/m_230_04.png\n","open_image/04/m_245_04.png\n","open_image/04/m_246_04.png\n","open_image/04/m_269_04.png\n","open_image/04/m_270_04.png\n","open_image/04/m_271_04.png\n","open_image/04/m_287_04.png\n","open_image/04/m_288_04.png\n","open_image/04/m_304_04.png\n","open_image/04/m_305_04.png\n","open_image/04/03-01-04-01-01-01-04.png\n","open_image/04/03-01-04-01-02-01-04.png\n","open_image/04/03-01-04-02-02-02-04.png\n","open_image/04/03-01-04-01-02-02-04.png\n","open_image/04/03-01-04-02-02-01-04.png\n","open_image/04/03-01-04-02-01-02-04.png\n","open_image/04/03-01-04-01-01-02-04.png\n","open_image/04/03-01-04-02-01-01-04.png\n","open_image/04/03-01-04-01-02-02-05.png\n","open_image/04/03-01-04-02-02-01-05.png\n","open_image/04/03-01-04-02-01-01-05.png\n","open_image/04/03-01-04-01-01-01-05.png\n","open_image/04/03-01-04-01-01-02-05.png\n","open_image/04/03-01-04-02-02-02-05.png\n","open_image/04/03-01-04-02-01-02-05.png\n","open_image/04/03-01-04-01-02-01-05.png\n","open_image/04/03-01-04-01-01-02-06.png\n","open_image/04/03-01-04-01-02-01-06.png\n","open_image/04/03-01-04-02-01-01-06.png\n","open_image/04/03-01-04-02-01-02-06.png\n","open_image/04/03-01-04-02-02-01-06.png\n","open_image/04/03-01-04-02-02-02-06.png\n","open_image/04/03-01-04-01-02-02-06.png\n","open_image/04/03-01-04-01-01-01-06.png\n","open_image/04/03-01-04-01-01-01-07.png\n","open_image/04/03-01-04-02-01-01-07.png\n","open_image/04/03-01-04-01-02-02-07.png\n","open_image/04/03-01-04-02-01-02-07.png\n","open_image/04/03-01-04-02-02-01-07.png\n","open_image/04/03-01-04-02-02-02-07.png\n","open_image/04/03-01-04-01-02-01-07.png\n","open_image/04/03-01-04-01-01-02-07.png\n","open_image/04/03-01-04-01-01-01-08.png\n","open_image/04/03-01-04-01-02-01-08.png\n","open_image/04/03-01-04-01-01-02-08.png\n","open_image/04/03-01-04-01-02-02-08.png\n","open_image/04/03-01-04-02-01-01-08.png\n","open_image/04/03-01-04-02-02-01-08.png\n","open_image/04/03-01-04-02-02-02-08.png\n","open_image/04/03-01-04-02-01-02-08.png\n","open_image/04/03-01-04-01-02-02-09.png\n","open_image/04/03-01-04-01-01-02-09.png\n","open_image/04/03-01-04-02-01-02-09.png\n","open_image/04/03-01-04-02-01-01-09.png\n","open_image/04/03-01-04-02-02-01-09.png\n","open_image/04/03-01-04-01-02-01-09.png\n","open_image/04/03-01-04-01-01-01-09.png\n","open_image/04/03-01-04-02-02-02-09.png\n","open_image/04/03-01-04-01-02-01-10.png\n","open_image/04/03-01-04-01-01-02-10.png\n","open_image/04/03-01-04-02-01-02-10.png\n","open_image/04/03-01-04-02-02-02-10.png\n","open_image/04/03-01-04-02-01-01-10.png\n","open_image/04/03-01-04-01-02-02-10.png\n","open_image/04/03-01-04-02-02-01-10.png\n","open_image/04/03-01-04-01-01-01-10.png\n","open_image/04/03-01-04-01-01-02-11.png\n","open_image/04/03-01-04-01-02-01-11.png\n","open_image/04/03-01-04-02-01-01-11.png\n","open_image/04/03-01-04-01-01-01-11.png\n","open_image/04/03-01-04-01-02-02-11.png\n","open_image/04/03-01-04-02-02-01-11.png\n","open_image/04/03-01-04-02-01-02-11.png\n","open_image/04/03-01-04-02-02-02-11.png\n","open_image/04/03-01-04-02-02-02-12.png\n","open_image/04/03-01-04-01-02-02-12.png\n","open_image/04/03-01-04-02-01-01-12.png\n","open_image/04/03-01-04-02-01-02-12.png\n","open_image/04/03-01-04-01-02-01-12.png\n","open_image/04/03-01-04-02-02-01-12.png\n","open_image/04/03-01-04-01-01-01-12.png\n","open_image/04/03-01-04-01-01-02-12.png\n","open_image/04/03-01-04-02-02-01-13.png\n","open_image/04/03-01-04-01-01-02-13.png\n","open_image/04/03-01-04-01-01-01-13.png\n","open_image/04/03-01-04-02-01-01-13.png\n","open_image/04/03-01-04-01-02-02-13.png\n","open_image/04/03-01-04-02-01-02-13.png\n","open_image/04/03-01-04-01-02-01-13.png\n","open_image/04/03-01-04-02-02-02-13.png\n","open_image/04/03-01-04-01-02-02-14.png\n","open_image/04/03-01-04-01-01-01-14.png\n","open_image/04/03-01-04-01-02-01-14.png\n","open_image/04/03-01-04-01-01-02-14.png\n","open_image/04/03-01-04-02-01-01-14.png\n","open_image/04/03-01-04-02-01-02-14.png\n","open_image/04/03-01-04-02-02-01-14.png\n","open_image/04/03-01-04-02-02-02-14.png\n","open_image/05/m_200_05.png\n","open_image/05/m_201_05.png\n","open_image/05/m_216_05.png\n","open_image/05/m_217_05.png\n","open_image/05/m_233_05.png\n","open_image/05/m_234_05.png\n","open_image/05/m_249_05.png\n","open_image/05/m_250_05.png\n","open_image/05/m_251_05.png\n","open_image/05/m_252_05.png\n","open_image/05/m_275_05.png\n","open_image/05/m_276_05.png\n","open_image/05/m_291_05.png\n","open_image/05/m_292_05.png\n","open_image/05/03-01-05-01-01-01-04.png\n","open_image/05/03-01-05-01-01-02-04.png\n","open_image/05/03-01-05-01-02-02-04.png\n","open_image/05/03-01-05-01-02-01-04.png\n","open_image/05/03-01-05-02-01-01-04.png\n","open_image/05/03-01-05-02-01-02-04.png\n","open_image/05/03-01-05-02-02-02-04.png\n","open_image/05/03-01-05-02-02-01-04.png\n","open_image/05/03-01-05-01-02-01-05.png\n","open_image/05/03-01-05-02-01-02-05.png\n","open_image/05/03-01-05-01-01-01-05.png\n","open_image/05/03-01-05-01-02-02-05.png\n","open_image/05/03-01-05-02-01-01-05.png\n","open_image/05/03-01-05-02-02-02-05.png\n","open_image/05/03-01-05-01-01-02-05.png\n","open_image/05/03-01-05-02-02-01-05.png\n","open_image/05/03-01-05-02-02-01-06.png\n","open_image/05/03-01-05-01-01-02-06.png\n","open_image/05/03-01-05-02-02-02-06.png\n","open_image/05/03-01-05-02-01-02-06.png\n","open_image/05/03-01-05-02-01-01-06.png\n","open_image/05/03-01-05-01-01-01-06.png\n","open_image/05/03-01-05-01-02-01-06.png\n","open_image/05/03-01-05-01-02-02-06.png\n","open_image/05/03-01-05-01-02-02-07.png\n","open_image/05/03-01-05-01-02-01-07.png\n","open_image/05/03-01-05-01-01-01-07.png\n","open_image/05/03-01-05-02-01-01-07.png\n","open_image/05/03-01-05-01-01-02-07.png\n","open_image/05/03-01-05-02-02-02-07.png\n","open_image/05/03-01-05-02-02-01-07.png\n","open_image/05/03-01-05-02-01-02-07.png\n","open_image/05/03-01-05-01-01-02-08.png\n","open_image/05/03-01-05-02-01-02-08.png\n","open_image/05/03-01-05-01-02-01-08.png\n","open_image/05/03-01-05-01-02-02-08.png\n","open_image/05/03-01-05-02-01-01-08.png\n","open_image/05/03-01-05-01-01-01-08.png\n","open_image/05/03-01-05-02-02-02-08.png\n","open_image/05/03-01-05-02-02-01-08.png\n","open_image/05/03-01-05-02-01-01-09.png\n","open_image/05/03-01-05-01-01-01-09.png\n","open_image/05/03-01-05-01-01-02-09.png\n","open_image/05/03-01-05-02-02-02-09.png\n","open_image/05/03-01-05-01-02-01-09.png\n","open_image/05/03-01-05-02-02-01-09.png\n","open_image/05/03-01-05-01-02-02-09.png\n","open_image/05/03-01-05-02-01-02-09.png\n","open_image/05/03-01-05-01-02-02-10.png\n","open_image/05/03-01-05-01-02-01-10.png\n","open_image/05/03-01-05-01-01-02-10.png\n","open_image/05/03-01-05-02-01-02-10.png\n","open_image/05/03-01-05-02-02-02-10.png\n","open_image/05/03-01-05-02-02-01-10.png\n","open_image/05/03-01-05-01-01-01-10.png\n","open_image/05/03-01-05-02-01-01-10.png\n","open_image/05/03-01-05-02-02-02-11.png\n","open_image/05/03-01-05-02-01-02-11.png\n","open_image/05/03-01-05-01-01-01-11.png\n","open_image/05/03-01-05-01-02-02-11.png\n","open_image/05/03-01-05-02-02-01-11.png\n","open_image/05/03-01-05-01-01-02-11.png\n","open_image/05/03-01-05-01-02-01-11.png\n","open_image/05/03-01-05-02-01-01-11.png\n","open_image/05/03-01-05-01-02-02-12.png\n","open_image/05/03-01-05-01-02-01-12.png\n","open_image/05/03-01-05-01-01-01-12.png\n","open_image/05/03-01-05-01-01-02-12.png\n","open_image/05/03-01-05-02-02-01-12.png\n","open_image/05/03-01-05-02-01-01-12.png\n","open_image/05/03-01-05-02-02-02-12.png\n","open_image/05/03-01-05-02-01-02-12.png\n","open_image/05/03-01-05-01-01-01-13.png\n","open_image/05/03-01-05-01-02-02-13.png\n","open_image/05/03-01-05-01-02-01-13.png\n","open_image/05/03-01-05-01-01-02-13.png\n","open_image/05/03-01-05-02-02-02-13.png\n","open_image/05/03-01-05-02-01-01-13.png\n","open_image/05/03-01-05-02-02-01-13.png\n","open_image/05/03-01-05-02-01-02-13.png\n","open_image/05/03-01-05-02-01-01-14.png\n","open_image/05/03-01-05-02-02-02-14.png\n","open_image/05/03-01-05-02-02-01-14.png\n","open_image/05/03-01-05-01-02-02-14.png\n","open_image/05/03-01-05-01-02-01-14.png\n","open_image/05/03-01-05-01-01-02-14.png\n","open_image/05/03-01-05-01-01-01-14.png\n","open_image/05/03-01-05-02-01-02-14.png\n","open_image/06/m_202_06.png\n","open_image/06/m_203_06.png\n","open_image/06/m_218_06.png\n","open_image/06/m_219_06.png\n","open_image/06/m_235_06.png\n","open_image/06/m_236_06.png\n","open_image/06/m_253_06.png\n","open_image/06/m_254_06.png\n","open_image/06/m_255_06.png\n","open_image/06/m_277_06.png\n","open_image/06/m_278_06.png\n","open_image/06/m_293_06.png\n","open_image/06/m_294_06.png\n","open_image/06/03-01-06-02-02-01-04.png\n","open_image/06/03-01-06-02-01-01-04.png\n","open_image/06/03-01-06-01-02-02-04.png\n","open_image/06/03-01-06-01-01-01-04.png\n","open_image/06/03-01-06-01-01-02-04.png\n","open_image/06/03-01-06-02-02-02-04.png\n","open_image/06/03-01-06-01-02-01-04.png\n","open_image/06/03-01-06-02-01-02-04.png\n","open_image/06/03-01-06-01-01-01-05.png\n","open_image/06/03-01-06-01-02-02-05.png\n","open_image/06/03-01-06-02-02-01-05.png\n","open_image/06/03-01-06-01-01-02-05.png\n","open_image/06/03-01-06-02-01-01-05.png\n","open_image/06/03-01-06-02-01-02-05.png\n","open_image/06/03-01-06-02-02-02-05.png\n","open_image/06/03-01-06-01-02-01-05.png\n","open_image/06/03-01-06-02-01-02-06.png\n","open_image/06/03-01-06-02-02-02-06.png\n","open_image/06/03-01-06-02-02-01-06.png\n","open_image/06/03-01-06-01-02-01-06.png\n","open_image/06/03-01-06-01-01-01-06.png\n","open_image/06/03-01-06-01-01-02-06.png\n","open_image/06/03-01-06-02-01-01-06.png\n","open_image/06/03-01-06-01-02-02-06.png\n","open_image/06/03-01-06-02-02-01-07.png\n","open_image/06/03-01-06-02-02-02-07.png\n","open_image/06/03-01-06-01-01-02-07.png\n","open_image/06/03-01-06-01-01-01-07.png\n","open_image/06/03-01-06-02-01-01-07.png\n","open_image/06/03-01-06-01-02-02-07.png\n","open_image/06/03-01-06-02-01-02-07.png\n","open_image/06/03-01-06-01-02-01-07.png\n","open_image/06/03-01-06-01-02-02-08.png\n","open_image/06/03-01-06-01-01-01-08.png\n","open_image/06/03-01-06-02-02-01-08.png\n","open_image/06/03-01-06-02-02-02-08.png\n","open_image/06/03-01-06-02-01-02-08.png\n","open_image/06/03-01-06-02-01-01-08.png\n","open_image/06/03-01-06-01-02-01-08.png\n","open_image/06/03-01-06-01-01-02-08.png\n","open_image/06/03-01-06-01-01-01-09.png\n","open_image/06/03-01-06-01-02-01-09.png\n","open_image/06/03-01-06-01-01-02-09.png\n","open_image/06/03-01-06-02-02-02-09.png\n","open_image/06/03-01-06-01-02-02-09.png\n","open_image/06/03-01-06-02-01-02-09.png\n","open_image/06/03-01-06-02-01-01-09.png\n","open_image/06/03-01-06-02-02-01-09.png\n","open_image/06/03-01-06-01-01-01-10.png\n","open_image/06/03-01-06-01-01-02-10.png\n","open_image/06/03-01-06-01-02-01-10.png\n","open_image/06/03-01-06-01-02-02-10.png\n","open_image/06/03-01-06-02-01-01-10.png\n","open_image/06/03-01-06-02-02-02-10.png\n","open_image/06/03-01-06-02-01-02-10.png\n","open_image/06/03-01-06-02-02-01-10.png\n","open_image/06/03-01-06-01-01-02-11.png\n","open_image/06/03-01-06-01-02-01-11.png\n","open_image/06/03-01-06-01-01-01-11.png\n","open_image/06/03-01-06-02-02-02-11.png\n","open_image/06/03-01-06-02-01-02-11.png\n","open_image/06/03-01-06-02-01-01-11.png\n","open_image/06/03-01-06-02-02-01-11.png\n","open_image/06/03-01-06-01-02-02-11.png\n","open_image/06/03-01-06-02-02-02-12.png\n","open_image/06/03-01-06-01-02-02-12.png\n","open_image/06/03-01-06-02-01-01-12.png\n","open_image/06/03-01-06-02-02-01-12.png\n","open_image/06/03-01-06-01-02-01-12.png\n","open_image/06/03-01-06-02-01-02-12.png\n","open_image/06/03-01-06-01-01-02-12.png\n","open_image/06/03-01-06-01-01-01-12.png\n","open_image/06/03-01-06-02-02-01-13.png\n","open_image/06/03-01-06-01-01-02-13.png\n","open_image/06/03-01-06-02-01-02-13.png\n","open_image/06/03-01-06-01-02-01-13.png\n","open_image/06/03-01-06-01-02-02-13.png\n","open_image/06/03-01-06-02-01-01-13.png\n","open_image/06/03-01-06-02-02-02-13.png\n","open_image/06/03-01-06-01-01-01-13.png\n","open_image/06/03-01-06-01-01-02-14.png\n","open_image/06/03-01-06-02-01-02-14.png\n","open_image/06/03-01-06-01-02-01-14.png\n","open_image/06/03-01-06-01-02-02-14.png\n","open_image/06/03-01-06-02-02-02-14.png\n","open_image/06/03-01-06-02-01-01-14.png\n","open_image/06/03-01-06-01-01-01-14.png\n","open_image/06/03-01-06-02-02-01-14.png\n","open_image/07/m_214_07.png\n","open_image/07/m_215_07.png\n","open_image/07/m_231_07.png\n","open_image/07/m_232_07.png\n","open_image/07/m_247_07.png\n","open_image/07/m_248_07.png\n","open_image/07/m_272_07.png\n","open_image/07/m_273_07.png\n","open_image/07/m_274_07.png\n","open_image/07/m_289_07.png\n","open_image/07/m_290_07.png\n","open_image/07/m_306_07.png\n","open_image/07/m_307_07.png\n","open_image/07/03-01-07-01-02-01-04.png\n","open_image/07/03-01-07-01-01-01-04.png\n","open_image/07/03-01-07-01-01-02-04.png\n","open_image/07/03-01-07-02-01-02-04.png\n","open_image/07/03-01-07-02-01-01-04.png\n","open_image/07/03-01-07-01-02-02-04.png\n","open_image/07/03-01-07-02-02-02-04.png\n","open_image/07/03-01-07-02-02-01-04.png\n","open_image/07/03-01-07-02-01-01-05.png\n","open_image/07/03-01-07-01-01-01-05.png\n","open_image/07/03-01-07-01-02-02-05.png\n","open_image/07/03-01-07-01-01-02-05.png\n","open_image/07/03-01-07-02-02-01-05.png\n","open_image/07/03-01-07-01-02-01-05.png\n","open_image/07/03-01-07-02-01-02-05.png\n","open_image/07/03-01-07-02-02-02-05.png\n","open_image/07/03-01-07-02-01-02-06.png\n","open_image/07/03-01-07-02-01-01-06.png\n","open_image/07/03-01-07-01-01-01-06.png\n","open_image/07/03-01-07-01-02-02-06.png\n","open_image/07/03-01-07-02-02-02-06.png\n","open_image/07/03-01-07-01-02-01-06.png\n","open_image/07/03-01-07-01-01-02-06.png\n","open_image/07/03-01-07-02-02-01-06.png\n","open_image/07/03-01-07-01-01-01-07.png\n","open_image/07/03-01-07-01-01-02-07.png\n","open_image/07/03-01-07-02-02-02-07.png\n","open_image/07/03-01-07-02-01-02-07.png\n","open_image/07/03-01-07-02-01-01-07.png\n","open_image/07/03-01-07-01-02-02-07.png\n","open_image/07/03-01-07-01-02-01-07.png\n","open_image/07/03-01-07-02-02-01-07.png\n","open_image/07/03-01-07-01-01-01-08.png\n","open_image/07/03-01-07-01-02-01-08.png\n","open_image/07/03-01-07-01-01-02-08.png\n","open_image/07/03-01-07-01-02-02-08.png\n","open_image/07/03-01-07-02-01-02-08.png\n","open_image/07/03-01-07-02-01-01-08.png\n","open_image/07/03-01-07-02-02-02-08.png\n","open_image/07/03-01-07-02-02-01-08.png\n","open_image/07/03-01-07-01-02-02-09.png\n","open_image/07/03-01-07-02-01-02-09.png\n","open_image/07/03-01-07-01-02-01-09.png\n","open_image/07/03-01-07-01-01-01-09.png\n","open_image/07/03-01-07-02-02-01-09.png\n","open_image/07/03-01-07-02-01-01-09.png\n","open_image/07/03-01-07-01-01-02-09.png\n","open_image/07/03-01-07-02-02-02-09.png\n","open_image/07/03-01-07-02-02-01-10.png\n","open_image/07/03-01-07-01-01-02-10.png\n","open_image/07/03-01-07-01-02-01-10.png\n","open_image/07/03-01-07-01-01-01-10.png\n","open_image/07/03-01-07-02-01-02-10.png\n","open_image/07/03-01-07-02-01-01-10.png\n","open_image/07/03-01-07-01-02-02-10.png\n","open_image/07/03-01-07-02-02-02-10.png\n","open_image/07/03-01-07-02-01-02-11.png\n","open_image/07/03-01-07-02-01-01-11.png\n","open_image/07/03-01-07-02-02-01-11.png\n","open_image/07/03-01-07-01-02-01-11.png\n","open_image/07/03-01-07-01-01-02-11.png\n","open_image/07/03-01-07-02-02-02-11.png\n","open_image/07/03-01-07-01-01-01-11.png\n","open_image/07/03-01-07-01-02-02-11.png\n","open_image/07/03-01-07-02-02-02-12.png\n","open_image/07/03-01-07-02-02-01-12.png\n","open_image/07/03-01-07-01-02-02-12.png\n","open_image/07/03-01-07-01-01-02-12.png\n","open_image/07/03-01-07-02-01-01-12.png\n","open_image/07/03-01-07-01-01-01-12.png\n","open_image/07/03-01-07-01-02-01-12.png\n","open_image/07/03-01-07-02-01-02-12.png\n","open_image/07/03-01-07-01-01-02-13.png\n","open_image/07/03-01-07-01-01-01-13.png\n","open_image/07/03-01-07-02-01-02-13.png\n","open_image/07/03-01-07-02-02-01-13.png\n","open_image/07/03-01-07-02-02-02-13.png\n","open_image/07/03-01-07-01-02-01-13.png\n","open_image/07/03-01-07-02-01-01-13.png\n","open_image/07/03-01-07-01-02-02-13.png\n","open_image/07/03-01-07-01-02-02-14.png\n","open_image/07/03-01-07-01-01-02-14.png\n","open_image/07/03-01-07-02-01-01-14.png\n","open_image/07/03-01-07-01-01-01-14.png\n","open_image/07/03-01-07-01-02-01-14.png\n","open_image/07/03-01-07-02-01-02-14.png\n","open_image/07/03-01-07-02-02-02-14.png\n","open_image/07/03-01-07-02-02-01-14.png\n","open_image/08/m_210_08.png\n","open_image/08/m_211_08.png\n","open_image/08/m_226_08.png\n","open_image/08/m_227_08.png\n","open_image/08/m_243_08.png\n","open_image/08/m_244_08.png\n","open_image/08/m_266_08.png\n","open_image/08/m_267_08.png\n","open_image/08/m_268_08.png\n","open_image/08/m_285_08.png\n","open_image/08/m_286_08.png\n","open_image/08/m_302_08.png\n","open_image/08/m_303_08.png\n","open_image/08/03-01-08-02-01-02-04.png\n","open_image/08/03-01-08-01-02-01-04.png\n","open_image/08/03-01-08-02-01-01-04.png\n","open_image/08/03-01-08-02-02-01-04.png\n","open_image/08/03-01-08-02-02-02-04.png\n","open_image/08/03-01-08-01-02-02-04.png\n","open_image/08/03-01-08-01-01-02-04.png\n","open_image/08/03-01-08-01-01-01-04.png\n","open_image/08/03-01-08-02-01-01-05.png\n","open_image/08/03-01-08-01-01-01-05.png\n","open_image/08/03-01-08-01-01-02-05.png\n","open_image/08/03-01-08-01-02-01-05.png\n","open_image/08/03-01-08-01-02-02-05.png\n","open_image/08/03-01-08-02-02-02-05.png\n","open_image/08/03-01-08-02-02-01-05.png\n","open_image/08/03-01-08-02-01-02-05.png\n","open_image/08/03-01-08-01-01-01-06.png\n","open_image/08/03-01-08-02-01-01-06.png\n","open_image/08/03-01-08-01-02-01-06.png\n","open_image/08/03-01-08-02-01-02-06.png\n","open_image/08/03-01-08-01-01-02-06.png\n","open_image/08/03-01-08-01-02-02-06.png\n","open_image/08/03-01-08-02-02-01-06.png\n","open_image/08/03-01-08-02-02-02-06.png\n","open_image/08/03-01-08-02-01-02-07.png\n","open_image/08/03-01-08-01-02-02-07.png\n","open_image/08/03-01-08-01-02-01-07.png\n","open_image/08/03-01-08-01-01-02-07.png\n","open_image/08/03-01-08-01-01-01-07.png\n","open_image/08/03-01-08-02-01-01-07.png\n","open_image/08/03-01-08-02-02-01-07.png\n","open_image/08/03-01-08-02-02-02-07.png\n","open_image/08/03-01-08-01-02-02-08.png\n","open_image/08/03-01-08-02-02-02-08.png\n","open_image/08/03-01-08-01-01-02-08.png\n","open_image/08/03-01-08-02-02-01-08.png\n","open_image/08/03-01-08-01-01-01-08.png\n","open_image/08/03-01-08-02-01-02-08.png\n","open_image/08/03-01-08-02-01-01-08.png\n","open_image/08/03-01-08-01-02-01-08.png\n","open_image/08/03-01-08-01-01-01-09.png\n","open_image/08/03-01-08-02-01-01-09.png\n","open_image/08/03-01-08-02-02-02-09.png\n","open_image/08/03-01-08-01-02-01-09.png\n","open_image/08/03-01-08-02-02-01-09.png\n","open_image/08/03-01-08-01-01-02-09.png\n","open_image/08/03-01-08-01-02-02-09.png\n","open_image/08/03-01-08-02-01-02-09.png\n","open_image/08/03-01-08-01-01-02-10.png\n","open_image/08/03-01-08-02-01-01-10.png\n","open_image/08/03-01-08-02-02-02-10.png\n","open_image/08/03-01-08-02-02-01-10.png\n","open_image/08/03-01-08-01-02-01-10.png\n","open_image/08/03-01-08-02-01-02-10.png\n","open_image/08/03-01-08-01-01-01-10.png\n","open_image/08/03-01-08-01-02-02-10.png\n","open_image/08/03-01-08-01-01-01-11.png\n","open_image/08/03-01-08-01-01-02-11.png\n","open_image/08/03-01-08-01-02-01-11.png\n","open_image/08/03-01-08-02-02-01-11.png\n","open_image/08/03-01-08-02-01-01-11.png\n","open_image/08/03-01-08-01-02-02-11.png\n","open_image/08/03-01-08-02-02-02-11.png\n","open_image/08/03-01-08-02-01-02-11.png\n","open_image/08/03-01-08-01-01-01-12.png\n","open_image/08/03-01-08-01-02-01-12.png\n","open_image/08/03-01-08-02-01-01-12.png\n","open_image/08/03-01-08-01-01-02-12.png\n","open_image/08/03-01-08-01-02-02-12.png\n","open_image/08/03-01-08-02-02-02-12.png\n","open_image/08/03-01-08-02-02-01-12.png\n","open_image/08/03-01-08-02-01-02-12.png\n","open_image/08/03-01-08-02-01-01-13.png\n","open_image/08/03-01-08-02-01-02-13.png\n","open_image/08/03-01-08-02-02-02-13.png\n","open_image/08/03-01-08-01-02-01-13.png\n","open_image/08/03-01-08-01-01-01-13.png\n","open_image/08/03-01-08-02-02-01-13.png\n","open_image/08/03-01-08-01-02-02-13.png\n","open_image/08/03-01-08-01-01-02-13.png\n","open_image/08/03-01-08-01-01-01-14.png\n","open_image/08/03-01-08-01-01-02-14.png\n","open_image/08/03-01-08-01-02-01-14.png\n","open_image/08/03-01-08-01-02-02-14.png\n","open_image/08/03-01-08-02-02-01-14.png\n","open_image/08/03-01-08-02-01-01-14.png\n","open_image/08/03-01-08-02-02-02-14.png\n","open_image/08/03-01-08-02-01-02-14.png\n","open_image/01/03-01-01-01-02-01-01.png\n","open_image/01/m_208_01.png\n","open_image/01/m_209_01.png\n","open_image/01/m_224_01.png\n","open_image/01/m_225_01.png\n","open_image/01/m_241_01.png\n","open_image/01/m_242_01.png\n","open_image/01/m_263_01.png\n","open_image/01/m_264_01.png\n","open_image/01/m_265_01.png\n","open_image/01/m_283_01.png\n","open_image/01/m_284_01.png\n","open_image/01/m_300_01.png\n","open_image/01/m_301_01.png\n","open_image/01/03-01-01-01-02-02-04.png\n","open_image/01/03-01-01-01-02-01-04.png\n","open_image/01/03-01-01-01-02-01-05.png\n","open_image/01/03-01-01-01-01-02-05.png\n","open_image/01/03-01-01-01-02-02-05.png\n","open_image/01/03-01-01-01-02-01-06.png\n","open_image/01/03-01-01-01-01-01-06.png\n","open_image/01/03-01-01-01-02-02-06.png\n","open_image/01/03-01-01-01-01-02-06.png\n","open_image/01/03-01-01-01-02-02-07.png\n","open_image/01/03-01-01-01-01-01-07.png\n","open_image/01/03-01-01-01-01-02-07.png\n","open_image/01/03-01-01-01-02-01-07.png\n","open_image/01/03-01-01-01-02-02-08.png\n","open_image/01/03-01-01-01-01-02-08.png\n","open_image/01/03-01-01-01-01-01-08.png\n","open_image/01/03-01-01-01-02-01-08.png\n","open_image/01/03-01-01-01-02-02-09.png\n","open_image/01/03-01-01-01-02-01-09.png\n","open_image/01/03-01-01-01-01-02-09.png\n","open_image/01/03-01-01-01-01-01-09.png\n","open_image/01/03-01-01-01-01-01-10.png\n","open_image/01/03-01-01-01-01-02-10.png\n","open_image/01/03-01-01-01-02-01-10.png\n","open_image/01/03-01-01-01-01-01-11.png\n","open_image/01/03-01-01-01-01-02-11.png\n","open_image/01/03-01-01-01-02-01-11.png\n","open_image/01/03-01-01-01-02-02-11.png\n","open_image/01/03-01-01-01-02-02-12.png\n","open_image/01/03-01-01-01-02-01-12.png\n","open_image/01/03-01-01-01-01-02-12.png\n","open_image/01/03-01-01-01-01-01-12.png\n","open_image/01/03-01-01-01-01-01-13.png\n","open_image/01/03-01-01-01-02-02-13.png\n","open_image/01/03-01-01-01-02-01-13.png\n","open_image/01/03-01-01-01-01-02-13.png\n","open_image/01/03-01-01-01-02-01-14.png\n","open_image/01/03-01-01-01-01-01-14.png\n","open_image/01/03-01-01-01-02-02-14.png\n","open_image/01/03-01-01-01-01-02-14.png\n","(544, 64, 64, 3)\n","(136, 64, 64, 3)\n","(544, 8)\n","(136, 8)\n","[[[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," ...\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]]\n"]}],"source":["# モデルの構築\n","import os\n","import cv2\n","import numpy as np\n","import glob as glob\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","\n","#フォルダをクラス名にする\n","path = \"open_image\"\n","folders = os.listdir(path)\n","\n","#フォルダ名を抽出\n","classes = [f for f in folders if os.path.isdir(os.path.join(path, f))]\n","n_classes = len(classes)\n","\n","#画像とラベルの格納\n","X = []\n","Y = []\n","\n","#画像を読み込みリサイズする\n","for label,class_name in enumerate(classes):\n","  files = glob.glob(path + \"/\" +  class_name + \"/*.png\")\n","\n","  for file in files:\n","    img = cv2.imread(file)\n","    print(file)\n","    img = cv2.resize(img,dsize=(64,64))\n","    X.append(img)\n","    Y.append(label)\n","\n","#精度を上げるために正規化\n","X = np.array(X)\n","X = X.astype('float32')\n","X /= 255.0\n","\n","#ラベルの変換\n","\n","Y = np.array(Y)\n","Y = np_utils.to_categorical(Y,n_classes)\n","Y[:5]\n","\n","#学習データとテストデータに分ける(テストデータ2割、学習データ8割)\n","X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n","\n","\n","#学習データ(8割)\n","print(X_train.shape)\n","#テストデータ(2割)\n","print(X_test.shape)\n","#学習データ(8割)\n","print(Y_train.shape)\n","#テストデータ(2割)\n","print(Y_test.shape)\n","\n","print(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5846,"status":"ok","timestamp":1673441692938,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"},"user_tz":-540},"id":"JaHYMjdaygv-","outputId":"f605c711-e7bb-4589-f42c-9c8195213dc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-layer-normalization\n","  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-layer-normalization) (1.21.6)\n","Building wheels for collected packages: keras-layer-normalization\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=d898a4b8e7c61b6dcd78efd119b377e114cc5657c08d6418b3e032cafff65fc3\n","  Stored in directory: /root/.cache/pip/wheels/d7/2b/f4/28f4bab995fa99c26b761bc7f9aeb5bf6c81e9be6ccd0b853b\n","Successfully built keras-layer-normalization\n","Installing collected packages: keras-layer-normalization\n","Successfully installed keras-layer-normalization-0.16.0\n"]}],"source":["!pip install keras-layer-normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":910,"status":"ok","timestamp":1673668340853,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"},"user_tz":-540},"id":"mHYj3dFuw-BH","outputId":"6c21782c-6b9a-423d-cc63-b82cd8e757cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["# layers= 20\n","Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 64, 64, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," sequential_1 (Sequential)   (None, 8)                 16392     \n","                                                                 \n","=================================================================\n","Total params: 14,731,080\n","Trainable params: 7,095,816\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"]}],"source":["from keras.applications.vgg16 import VGG16\n","from keras.models import Sequential\n","from keras.models import model_from_json\n","from keras.models import Model\n","from keras.layers import Input, Activation, Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","#vgg16\n","input_tensor = Input(shape=(64,64,3))\n","#最後の1000の層を省く\n","base_model = VGG16(weights='imagenet', input_tensor=input_tensor,include_top=False)\n","\n","\n","#後付けで入れたい層の作成\n","top_model = Sequential()\n","top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n","top_model.add(Dense(n_classes, activation='softmax'))\n","\n","\n","#結合\n","model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n","\n","\n","#学習させない層\n","for layer in model.layers[:15]:\n","  layer.trainable = False\n","\n","print('# layers=', len(model.layers))\n","\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42642,"status":"ok","timestamp":1673668393086,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"},"user_tz":-540},"id":"umrKWIaIy5XU","outputId":"8a5f88d8-fc84-423d-d3aa-ecf06f5a0b40"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","69/69 [==============================] - 3s 19ms/step - loss: 2.1321 - accuracy: 0.1332\n","Epoch 2/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0765 - accuracy: 0.1395\n","Epoch 3/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0744 - accuracy: 0.1395\n","Epoch 4/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0726 - accuracy: 0.1395\n","Epoch 5/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0712 - accuracy: 0.1395\n","Epoch 6/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0698 - accuracy: 0.1395\n","Epoch 7/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0686 - accuracy: 0.1395\n","Epoch 8/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0678 - accuracy: 0.1395\n","Epoch 9/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0670 - accuracy: 0.1395\n","Epoch 10/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0664 - accuracy: 0.1395\n","Epoch 11/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0660 - accuracy: 0.1159\n","Epoch 12/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0654 - accuracy: 0.1395\n","Epoch 13/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0649 - accuracy: 0.1395\n","Epoch 14/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0647 - accuracy: 0.1395\n","Epoch 15/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0644 - accuracy: 0.1395\n","Epoch 16/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0641 - accuracy: 0.1395\n","Epoch 17/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0638 - accuracy: 0.1395\n","Epoch 18/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0638 - accuracy: 0.1395\n","Epoch 19/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0636 - accuracy: 0.1295\n","Epoch 20/20\n","69/69 [==============================] - 1s 18ms/step - loss: 2.0634 - accuracy: 0.1404\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0d60044bb0>"]},"metadata":{},"execution_count":9}],"source":["#学習データで学習\n","model.fit(X_train, Y_train, epochs=20, batch_size=16)\n","\n","#テストデータで精度確認\n","# score = model.evaluate(X_test, Y_test, batch_size=16)"]},{"cell_type":"code","source":["from keras.models import load_model\n","import pickle\n","import cv2\n","model = load_model('cnn.h5')\n","print(Y_test)\n","\n","# testの精度を出す！"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsC9_9elTgf5","executionInfo":{"status":"ok","timestamp":1673586359687,"user_tz":-540,"elapsed":1706,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"2083ff4d-3ce4-4fa3-a848-3a9119473187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1.]]\n"]}]},{"cell_type":"code","source":["\n","data = model.predict(X_test)\n","a = []\n","b = []\n","for i in data:\n","  a.append(np.argmax(i))\n","for j in Y_test:\n","  b.append(np.argmax(j))\n","print(a)\n","print(b)\n","a = np.array(a)\n","b = np.array(b)\n","c = a == b\n","count = 0\n","for k in c:\n","  if k == True:\n","    count+=1\n","print(count/len(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prg7v1fpYefa","executionInfo":{"status":"ok","timestamp":1673668752648,"user_tz":-540,"elapsed":606,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"00e213f8-48e0-499a-eb7e-9073909aba1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["9/9 [==============================] - 0s 20ms/step\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[7, 3, 1, 3, 2, 0, 7, 4, 7, 4, 1, 3, 4, 7, 5, 7, 2, 1, 4, 0, 4, 3, 4, 5, 3, 4, 7, 3, 6, 4, 6, 2, 3, 4, 2, 7, 1, 2, 3, 6, 1, 7, 3, 3, 6, 7, 2, 0, 5, 5, 7, 7, 5, 5, 4, 7, 3, 2, 4, 6, 5, 4, 5, 4, 4, 4, 6, 1, 3, 3, 6, 1, 5, 4, 7, 6, 7, 0, 5, 4, 2, 4, 7, 6, 6, 7, 4, 2, 3, 4, 1, 6, 5, 5, 2, 4, 0, 5, 4, 6, 1, 1, 6, 5, 4, 7, 5, 5, 3, 1, 4, 7, 7, 3, 5, 3, 2, 6, 2, 5, 7, 7, 3, 7, 2, 5, 3, 3, 3, 1, 6, 2, 3, 3, 6, 5, 4, 3, 2, 2, 1, 2, 6, 4, 6, 5, 3, 1, 7, 6, 5, 1, 6, 2, 6, 5, 0, 3, 4, 5, 6, 5, 7, 4, 2, 3, 7, 7, 1, 4, 3, 4, 7, 1, 7, 1, 5, 2, 6, 3, 1, 5, 3, 7, 4, 1, 0, 6, 4, 5, 4, 2, 6, 2, 4, 5, 3, 3, 1, 5, 4, 5, 1, 3, 6, 2, 6, 4, 5, 1, 5, 7, 4, 1, 0, 6, 6, 7, 1, 1, 0, 2, 6, 5, 0, 1, 3, 7, 4, 7, 5, 7, 6, 0, 1, 7, 2, 6, 4, 7, 4, 5, 0, 5, 7, 1, 7, 2, 2, 4, 2, 3, 4, 4, 7, 4, 3, 2, 3, 6, 1, 0, 6, 7, 3, 3, 4, 2, 0, 4, 0, 3, 6, 4, 6, 2]\n","0.10869565217391304\n"]}]},{"cell_type":"code","source":["from keras.models import load_model\n","import pickle\n","import cv2\n","\n","#モデルとクラス名の読み込み\n","model = load_model('cnn.h5')\n","classes = pickle.load(open('classes.sav', 'rb'))\n","\n","#sample画像の前処理\n","img = cv2.imread('m_110_01.png')\n","img = cv2.resize(img,dsize=(64,64))\n","img = img.astype('float32')\n","img /= 255.0\n","img = img[None, ...]\n","\n","result = model.predict(img)\n","\n","#確率が一番大きいクラス\n","pred = result.argmax()\n","\n","print(pred)\n","\n","img = cv2.imread(file)\n","cv2.imwrite('output/' + str(classes[pred]) + '/' + file,img)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"1Pwa_5iUYGlY","executionInfo":{"status":"error","timestamp":1673587569282,"user_tz":-540,"elapsed":2698,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"4af39cdb-0102-4677-e6eb-7b0545591c08"},"execution_count":null,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-eb8b13636f02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#sample画像の前処理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm_110_01.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"]}]},{"cell_type":"code","source":["import pickle\n","#クラス名の保存\n","pickle.dump(classes, open('classes2.sav', 'wb'))\n","#モデルの保存\n","model.save('cnn2.h5')"],"metadata":{"id":"eYgmfr8oXqXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ちっちゃいデータのモデル\n","from keras.models import load_model\n","import pickle\n","import cv2\n","model = load_model('cnn.h5')\n","classes = pickle.load(open('classes.sav', 'rb'))\n","\n","data = model.predict(X_test)\n","a = []\n","b = []\n","for i in data:\n","  a.append(np.argmax(i))\n","for j in Y_test:\n","  b.append(np.argmax(j))\n","print(a)\n","print(b)\n","a = np.array(a)\n","b = np.array(b)\n","c = a == b\n","count = 0\n","for k in c:\n","  if k == True:\n","    count+=1\n","print(count/len(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sI7cOKV_EBAa","executionInfo":{"status":"ok","timestamp":1673595957010,"user_tz":-540,"elapsed":1410,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"9da4c18f-2d63-47a5-ead2-c4a0f46728f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6a7c350430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 156ms/step\n","[2, 4, 1, 5, 1, 0, 0, 7, 6, 2, 1, 2, 6, 1, 5, 2, 2, 1, 2, 0, 0]\n","[3, 2, 3, 5, 1, 0, 0, 4, 5, 2, 1, 1, 3, 1, 5, 5, 6, 7, 1, 0, 0]\n","0.47619047619047616\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nrtmkWlPch_M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ここまで没コード<br>\n","============================================================================\n","# 以下OKコード"],"metadata":{"id":"kH92bu3McjHh"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.optimizers import RMSprop # TensorFlow1系\n","# from keras.optimizers import RMSprop # エラー（ImportError: cannot import name 'RMSprop' from 'keras.optimizers' (/usr/local/lib/python3.7/dist-packages/keras/optimizers.py)）が発生\n","# from tensorflow.keras.optimizers import RMSprop # TensorFlow2系\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","from keras.utils import np_utils\n","import keras\n","import numpy as np\n","\n","num_classes = len(classes)\n","image_size = 64\n","\n","\"\"\"\n","モデルを学習する関数\n","\"\"\"\n","def train(X, y, X_test, y_test):\n","    params = {\n","    'horizontal_flip': True,\n","    'height_shift_range': 0.1,\n","    'width_shift_range': 0.1,\n","    }\n","    generator = keras.preprocessing.image.ImageDataGenerator(**params)\n","\n","    train_iter = generator.flow(x=X, y=y)\n","    model = Sequential()\n","\n","    # Xは(1200, 64, 64, 3)\n","    # X.shape[1:]とすることで、(64, 64, 3)となり、入力にすることが可能です。\n","    model.add(Conv2D(32,(3,3), padding='same',input_shape=X.shape[1:]))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(32,(3,3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.1))\n","\n","    model.add(Conv2D(64,(3,3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64,(3,3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.45))\n","    model.add(Dense(8)) # 8感情に分ける\n","    model.add(Activation('softmax'))\n","\n","    # https://keras.io/ja/optimizers/\n","    # 今回は、最適化アルゴリズムにRMSpropを利用\n","    opt = RMSprop(lr=0.00005, decay=1e-6)\n","    # https://keras.io/ja/models/sequential/\n","    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n","    model.fit(X,y, batch_size=28, epochs=300)\n","    # HDF5ファイルにKerasのモデルを保存\n","    model.save('./cnn_no_200.h5')\n","\n","    return model\n","\n","\"\"\"\n","メイン関数\n","データの読み込みとモデルの学習を行います。\n","\"\"\"\n","def main():\n","    # データの読み込み\n","    # X_train, y_train, X_test, y_test = X_train,Y_train,X_test,Y_test\n","\n","    # モデルの学習\n","    model = train(X_train, Y_train, X_test, Y_test)\n","\n","main()"],"metadata":{"id":"9n892iQ6alH5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675141295070,"user_tz":-540,"elapsed":148869,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"b18c9f4e-da11-480a-888b-99affa8c645b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["20/20 [==============================] - 9s 22ms/step - loss: 2.0567 - accuracy: 0.1452\n","Epoch 2/300\n","20/20 [==============================] - 0s 12ms/step - loss: 2.0144 - accuracy: 0.1618\n","Epoch 3/300\n","20/20 [==============================] - 0s 13ms/step - loss: 2.0012 - accuracy: 0.1673\n","Epoch 4/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.9782 - accuracy: 0.2004\n","Epoch 5/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.9679 - accuracy: 0.1857\n","Epoch 6/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.9565 - accuracy: 0.2114\n","Epoch 7/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.9484 - accuracy: 0.2188\n","Epoch 8/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.9218 - accuracy: 0.1838\n","Epoch 9/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.9268 - accuracy: 0.2132\n","Epoch 10/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.8958 - accuracy: 0.2408\n","Epoch 11/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.8756 - accuracy: 0.2537\n","Epoch 12/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.8479 - accuracy: 0.2776\n","Epoch 13/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.8161 - accuracy: 0.3015\n","Epoch 14/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.8115 - accuracy: 0.3015\n","Epoch 15/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.7787 - accuracy: 0.2941\n","Epoch 16/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.7612 - accuracy: 0.3235\n","Epoch 17/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.7603 - accuracy: 0.3346\n","Epoch 18/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.6989 - accuracy: 0.3585\n","Epoch 19/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.7032 - accuracy: 0.3603\n","Epoch 20/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.6746 - accuracy: 0.3456\n","Epoch 21/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.6400 - accuracy: 0.3548\n","Epoch 22/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.6403 - accuracy: 0.3272\n","Epoch 23/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.6217 - accuracy: 0.3695\n","Epoch 24/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.5734 - accuracy: 0.4154\n","Epoch 25/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.5368 - accuracy: 0.4118\n","Epoch 26/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.5765 - accuracy: 0.3879\n","Epoch 27/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.5364 - accuracy: 0.3952\n","Epoch 28/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.4949 - accuracy: 0.4191\n","Epoch 29/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.4874 - accuracy: 0.4338\n","Epoch 30/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.4810 - accuracy: 0.4265\n","Epoch 31/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.4497 - accuracy: 0.4522\n","Epoch 32/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.4620 - accuracy: 0.4393\n","Epoch 33/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.4122 - accuracy: 0.4577\n","Epoch 34/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.4077 - accuracy: 0.4430\n","Epoch 35/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.3940 - accuracy: 0.4614\n","Epoch 36/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.3939 - accuracy: 0.4467\n","Epoch 37/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.3666 - accuracy: 0.5037\n","Epoch 38/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.3553 - accuracy: 0.4945\n","Epoch 39/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.3177 - accuracy: 0.5055\n","Epoch 40/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.3311 - accuracy: 0.5147\n","Epoch 41/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.3123 - accuracy: 0.5129\n","Epoch 42/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.2948 - accuracy: 0.5202\n","Epoch 43/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.2613 - accuracy: 0.5349\n","Epoch 44/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.2769 - accuracy: 0.5129\n","Epoch 45/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.2343 - accuracy: 0.5312\n","Epoch 46/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.2495 - accuracy: 0.5441\n","Epoch 47/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1859 - accuracy: 0.5404\n","Epoch 48/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1919 - accuracy: 0.5790\n","Epoch 49/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1539 - accuracy: 0.5790\n","Epoch 50/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1683 - accuracy: 0.5864\n","Epoch 51/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1403 - accuracy: 0.5846\n","Epoch 52/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1560 - accuracy: 0.5882\n","Epoch 53/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.1177 - accuracy: 0.5846\n","Epoch 54/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.0892 - accuracy: 0.6048\n","Epoch 55/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.0877 - accuracy: 0.6324\n","Epoch 56/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.0895 - accuracy: 0.6066\n","Epoch 57/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.0596 - accuracy: 0.6287\n","Epoch 58/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.0564 - accuracy: 0.6195\n","Epoch 59/300\n","20/20 [==============================] - 0s 12ms/step - loss: 1.0416 - accuracy: 0.6434\n","Epoch 60/300\n","20/20 [==============================] - 0s 13ms/step - loss: 1.0379 - accuracy: 0.6360\n","Epoch 61/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.9883 - accuracy: 0.6746\n","Epoch 62/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.9779 - accuracy: 0.6562\n","Epoch 63/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.9797 - accuracy: 0.6471\n","Epoch 64/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.9477 - accuracy: 0.6544\n","Epoch 65/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.9390 - accuracy: 0.6746\n","Epoch 66/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.9185 - accuracy: 0.6838\n","Epoch 67/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.8883 - accuracy: 0.6912\n","Epoch 68/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.9052 - accuracy: 0.6691\n","Epoch 69/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.8803 - accuracy: 0.6930\n","Epoch 70/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.8765 - accuracy: 0.6691\n","Epoch 71/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.8562 - accuracy: 0.7151\n","Epoch 72/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.8452 - accuracy: 0.6893\n","Epoch 73/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.8580 - accuracy: 0.7059\n","Epoch 74/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.8194 - accuracy: 0.7188\n","Epoch 75/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.8357 - accuracy: 0.7059\n","Epoch 76/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7860 - accuracy: 0.7224\n","Epoch 77/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7855 - accuracy: 0.7224\n","Epoch 78/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7781 - accuracy: 0.7335\n","Epoch 79/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.7512 - accuracy: 0.7261\n","Epoch 80/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7694 - accuracy: 0.7298\n","Epoch 81/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7368 - accuracy: 0.7500\n","Epoch 82/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7161 - accuracy: 0.7555\n","Epoch 83/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.7036 - accuracy: 0.7665\n","Epoch 84/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.6731 - accuracy: 0.7868\n","Epoch 85/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.6942 - accuracy: 0.7555\n","Epoch 86/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.6688 - accuracy: 0.7702\n","Epoch 87/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.6319 - accuracy: 0.7757\n","Epoch 88/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.6529 - accuracy: 0.7647\n","Epoch 89/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.6361 - accuracy: 0.7794\n","Epoch 90/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.6185 - accuracy: 0.8015\n","Epoch 91/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5994 - accuracy: 0.8070\n","Epoch 92/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5996 - accuracy: 0.8015\n","Epoch 93/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5729 - accuracy: 0.8180\n","Epoch 94/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 0.7996\n","Epoch 95/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5921 - accuracy: 0.8033\n","Epoch 96/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5930 - accuracy: 0.8033\n","Epoch 97/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5477 - accuracy: 0.8327\n","Epoch 98/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.5271 - accuracy: 0.8346\n","Epoch 99/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5762 - accuracy: 0.7941\n","Epoch 100/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5178 - accuracy: 0.8401\n","Epoch 101/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4967 - accuracy: 0.8364\n","Epoch 102/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5097 - accuracy: 0.8327\n","Epoch 103/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5173 - accuracy: 0.8272\n","Epoch 104/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5221 - accuracy: 0.8125\n","Epoch 105/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4797 - accuracy: 0.8493\n","Epoch 106/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.5198 - accuracy: 0.8217\n","Epoch 107/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4237 - accuracy: 0.8824\n","Epoch 108/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4312 - accuracy: 0.8713\n","Epoch 109/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4234 - accuracy: 0.8621\n","Epoch 110/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4246 - accuracy: 0.8787\n","Epoch 111/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.4312 - accuracy: 0.8511\n","Epoch 112/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4067 - accuracy: 0.8658\n","Epoch 113/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4175 - accuracy: 0.8640\n","Epoch 114/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.8860\n","Epoch 115/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3907 - accuracy: 0.8676\n","Epoch 116/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3732 - accuracy: 0.8824\n","Epoch 117/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3862 - accuracy: 0.8676\n","Epoch 118/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3683 - accuracy: 0.8860\n","Epoch 119/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3641 - accuracy: 0.8768\n","Epoch 120/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.3578 - accuracy: 0.8915\n","Epoch 121/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3597 - accuracy: 0.8860\n","Epoch 122/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3314 - accuracy: 0.8989\n","Epoch 123/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3442 - accuracy: 0.8879\n","Epoch 124/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3178 - accuracy: 0.9062\n","Epoch 125/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.3393 - accuracy: 0.9026\n","Epoch 126/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2963 - accuracy: 0.9136\n","Epoch 127/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3244 - accuracy: 0.9026\n","Epoch 128/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2837 - accuracy: 0.9191\n","Epoch 129/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.3118 - accuracy: 0.9007\n","Epoch 130/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2822 - accuracy: 0.9210\n","Epoch 131/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2704 - accuracy: 0.9357\n","Epoch 132/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2547 - accuracy: 0.9210\n","Epoch 133/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2703 - accuracy: 0.9173\n","Epoch 134/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2909 - accuracy: 0.9044\n","Epoch 135/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2587 - accuracy: 0.9191\n","Epoch 136/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2563 - accuracy: 0.9210\n","Epoch 137/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9338\n","Epoch 138/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2557 - accuracy: 0.9154\n","Epoch 139/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2674 - accuracy: 0.9173\n","Epoch 140/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2581 - accuracy: 0.9210\n","Epoch 141/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2074 - accuracy: 0.9393\n","Epoch 142/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.2309 - accuracy: 0.9228\n","Epoch 143/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1924 - accuracy: 0.9485\n","Epoch 144/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2172 - accuracy: 0.9283\n","Epoch 145/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2062 - accuracy: 0.9393\n","Epoch 146/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2104 - accuracy: 0.9449\n","Epoch 147/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.1839 - accuracy: 0.9393\n","Epoch 148/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2128 - accuracy: 0.9301\n","Epoch 149/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.2095 - accuracy: 0.9504\n","Epoch 150/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1794 - accuracy: 0.9430\n","Epoch 151/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1644 - accuracy: 0.9522\n","Epoch 152/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1700 - accuracy: 0.9540\n","Epoch 153/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1602 - accuracy: 0.9651\n","Epoch 154/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1825 - accuracy: 0.9430\n","Epoch 155/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1741 - accuracy: 0.9540\n","Epoch 156/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.1769 - accuracy: 0.9375\n","Epoch 157/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1331 - accuracy: 0.9688\n","Epoch 158/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1365 - accuracy: 0.9724\n","Epoch 159/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1573 - accuracy: 0.9412\n","Epoch 160/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1522 - accuracy: 0.9430\n","Epoch 161/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1548 - accuracy: 0.9504\n","Epoch 162/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1326 - accuracy: 0.9743\n","Epoch 163/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1358 - accuracy: 0.9559\n","Epoch 164/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1320 - accuracy: 0.9669\n","Epoch 165/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9504\n","Epoch 166/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1380 - accuracy: 0.9651\n","Epoch 167/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1486 - accuracy: 0.9522\n","Epoch 168/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1192 - accuracy: 0.9706\n","Epoch 169/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.1363 - accuracy: 0.9669\n","Epoch 170/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1275 - accuracy: 0.9632\n","Epoch 171/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1067 - accuracy: 0.9761\n","Epoch 172/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1312 - accuracy: 0.9669\n","Epoch 173/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0997 - accuracy: 0.9688\n","Epoch 174/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1014 - accuracy: 0.9706\n","Epoch 175/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1040 - accuracy: 0.9779\n","Epoch 176/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1101 - accuracy: 0.9669\n","Epoch 177/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1087 - accuracy: 0.9632\n","Epoch 178/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0980 - accuracy: 0.9779\n","Epoch 179/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1254 - accuracy: 0.9577\n","Epoch 180/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1112 - accuracy: 0.9651\n","Epoch 181/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.0746 - accuracy: 0.9835\n","Epoch 182/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9779\n","Epoch 183/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.1053 - accuracy: 0.9706\n","Epoch 184/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0686 - accuracy: 0.9853\n","Epoch 185/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.0917 - accuracy: 0.9706\n","Epoch 186/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0741 - accuracy: 0.9798\n","Epoch 187/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0793 - accuracy: 0.9798\n","Epoch 188/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0876 - accuracy: 0.9688\n","Epoch 189/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0869 - accuracy: 0.9779\n","Epoch 190/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.0615 - accuracy: 0.9871\n","Epoch 191/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0821 - accuracy: 0.9779\n","Epoch 192/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0720 - accuracy: 0.9761\n","Epoch 193/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0689 - accuracy: 0.9798\n","Epoch 194/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0776 - accuracy: 0.9761\n","Epoch 195/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0795 - accuracy: 0.9871\n","Epoch 196/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0673 - accuracy: 0.9890\n","Epoch 197/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0567 - accuracy: 0.9890\n","Epoch 198/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0636 - accuracy: 0.9871\n","Epoch 199/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0559 - accuracy: 0.9890\n","Epoch 200/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0634 - accuracy: 0.9816\n","Epoch 201/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0685 - accuracy: 0.9779\n","Epoch 202/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0622 - accuracy: 0.9835\n","Epoch 203/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9926\n","Epoch 204/300\n","20/20 [==============================] - 0s 15ms/step - loss: 0.0558 - accuracy: 0.9835\n","Epoch 205/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0725 - accuracy: 0.9798\n","Epoch 206/300\n","20/20 [==============================] - 0s 15ms/step - loss: 0.0680 - accuracy: 0.9816\n","Epoch 207/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0624 - accuracy: 0.9816\n","Epoch 208/300\n","20/20 [==============================] - 0s 15ms/step - loss: 0.0463 - accuracy: 0.9890\n","Epoch 209/300\n","20/20 [==============================] - 0s 15ms/step - loss: 0.0561 - accuracy: 0.9853\n","Epoch 210/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0502 - accuracy: 0.9926\n","Epoch 211/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0477 - accuracy: 0.9871\n","Epoch 212/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0404 - accuracy: 0.9908\n","Epoch 213/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0653 - accuracy: 0.9761\n","Epoch 214/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0483 - accuracy: 0.9908\n","Epoch 215/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0533 - accuracy: 0.9853\n","Epoch 216/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0526 - accuracy: 0.9890\n","Epoch 217/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0428 - accuracy: 0.9871\n","Epoch 218/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0522 - accuracy: 0.9816\n","Epoch 219/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0411 - accuracy: 0.9908\n","Epoch 220/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0489 - accuracy: 0.9853\n","Epoch 221/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0352 - accuracy: 0.9963\n","Epoch 222/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0372 - accuracy: 0.9945\n","Epoch 223/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0360 - accuracy: 0.9890\n","Epoch 224/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0288 - accuracy: 0.9945\n","Epoch 225/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0393 - accuracy: 0.9926\n","Epoch 226/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0412 - accuracy: 0.9908\n","Epoch 227/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0462 - accuracy: 0.9853\n","Epoch 228/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0427 - accuracy: 0.9945\n","Epoch 229/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0352 - accuracy: 0.9926\n","Epoch 230/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0210 - accuracy: 1.0000\n","Epoch 231/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0471 - accuracy: 0.9853\n","Epoch 232/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0517 - accuracy: 0.9853\n","Epoch 233/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0328 - accuracy: 0.9908\n","Epoch 234/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0473 - accuracy: 0.9835\n","Epoch 235/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0163 - accuracy: 1.0000\n","Epoch 236/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0355 - accuracy: 0.9926\n","Epoch 237/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0449 - accuracy: 0.9853\n","Epoch 238/300\n","20/20 [==============================] - 0s 12ms/step - loss: 0.0476 - accuracy: 0.9853\n","Epoch 239/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0421 - accuracy: 0.9871\n","Epoch 240/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.9963\n","Epoch 241/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0231 - accuracy: 0.9963\n","Epoch 242/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9890\n","Epoch 243/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 0.9908\n","Epoch 244/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0274 - accuracy: 0.9908\n","Epoch 245/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0301 - accuracy: 0.9908\n","Epoch 246/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0245 - accuracy: 0.9945\n","Epoch 247/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0272 - accuracy: 0.9945\n","Epoch 248/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0322 - accuracy: 0.9871\n","Epoch 249/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0307 - accuracy: 0.9926\n","Epoch 250/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0348 - accuracy: 0.9908\n","Epoch 251/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9908\n","Epoch 252/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0244 - accuracy: 0.9963\n","Epoch 253/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 1.0000\n","Epoch 254/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0329 - accuracy: 0.9871\n","Epoch 255/300\n","20/20 [==============================] - 0s 14ms/step - loss: 0.0391 - accuracy: 0.9835\n","Epoch 256/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0250 - accuracy: 0.9963\n","Epoch 257/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9945\n","Epoch 258/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0235 - accuracy: 0.9908\n","Epoch 259/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0137 - accuracy: 0.9963\n","Epoch 260/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0227 - accuracy: 0.9963\n","Epoch 261/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0256 - accuracy: 0.9926\n","Epoch 262/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0159 - accuracy: 0.9982\n","Epoch 263/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.9963\n","Epoch 264/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0318 - accuracy: 0.9871\n","Epoch 265/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9982\n","Epoch 266/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.9945\n","Epoch 267/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0254 - accuracy: 0.9890\n","Epoch 268/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0169 - accuracy: 0.9963\n","Epoch 269/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 0.9963\n","Epoch 270/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9945\n","Epoch 271/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 0.9982\n","Epoch 272/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0226 - accuracy: 0.9945\n","Epoch 273/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0151 - accuracy: 0.9963\n","Epoch 274/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.9963\n","Epoch 275/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0175 - accuracy: 0.9982\n","Epoch 276/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0178 - accuracy: 0.9945\n","Epoch 277/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9926\n","Epoch 278/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0257 - accuracy: 0.9926\n","Epoch 279/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0160 - accuracy: 0.9963\n","Epoch 280/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0205 - accuracy: 0.9926\n","Epoch 281/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.9908\n","Epoch 282/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 283/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0194 - accuracy: 0.9982\n","Epoch 284/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 1.0000\n","Epoch 285/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0140 - accuracy: 0.9982\n","Epoch 286/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0176 - accuracy: 0.9945\n","Epoch 287/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9945\n","Epoch 288/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.9963\n","Epoch 289/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0200 - accuracy: 0.9945\n","Epoch 290/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0079 - accuracy: 1.0000\n","Epoch 291/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0072 - accuracy: 1.0000\n","Epoch 292/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.9963\n","Epoch 293/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 0.9982\n","Epoch 294/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0126 - accuracy: 0.9963\n","Epoch 295/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0152 - accuracy: 0.9963\n","Epoch 296/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0174 - accuracy: 0.9945\n","Epoch 297/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0283 - accuracy: 0.9890\n","Epoch 298/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0141 - accuracy: 0.9963\n","Epoch 299/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 1.0000\n","Epoch 300/300\n","20/20 [==============================] - 0s 13ms/step - loss: 0.0170 - accuracy: 0.9963\n"]}]},{"cell_type":"code","source":["from keras.models import load_model\n","import pickle\n","import cv2\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","\n","model = load_model('cnn_no_200.h5')\n","# classes = pickle.load(open('classes.sav', 'rb'))\n","\n","data = model.predict(X_test)\n","for k in range(len(data)):\n","  a_argsorted = np.argsort(data[k], axis=0)\n","  print(a_argsorted)\n","  \n","\n","a = []\n","b = []\n","for i in data:\n","  a.append(np.argmax(i))\n","for j in Y_test:\n","  b.append(np.argmax(j))\n","print(b)\n","print(a)\n","a = np.array(a)\n","b = np.array(b)\n","c = a == b\n","count = 0\n","for k in c:\n","  if k == True:\n","    count+=1\n","print(count/len(c))\n","print(accuracy_score(a, b))\n","print(confusion_matrix(a, b))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mysLif6bwtN","executionInfo":{"status":"ok","timestamp":1675141817231,"user_tz":-540,"elapsed":1244,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"a684cfb1-c603-41ae-e7f3-4ed16e77701e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["5/5 [==============================] - 0s 6ms/step\n","[7 1 5 2 3 0 4 6]\n","[3 1 7 0 6 2 5 4]\n","[3 1 4 6 0 7 5 2]\n","[6 4 1 5 2 3 7 0]\n","[1 5 3 6 4 0 7 2]\n","[7 0 1 4 3 6 2 5]\n","[7 4 1 2 0 6 3 5]\n","[6 5 4 2 7 3 0 1]\n","[1 3 6 0 2 5 7 4]\n","[2 7 3 4 6 5 1 0]\n","[7 3 5 2 1 0 6 4]\n","[1 7 4 5 6 2 3 0]\n","[5 7 3 2 1 6 0 4]\n","[3 1 0 7 5 2 6 4]\n","[7 3 1 0 2 4 6 5]\n","[2 7 4 0 1 6 5 3]\n","[6 3 1 5 0 4 7 2]\n","[1 7 6 3 4 2 5 0]\n","[1 7 2 5 6 4 0 3]\n","[4 6 0 1 5 3 7 2]\n","[2 7 1 6 5 0 4 3]\n","[1 2 7 5 3 6 0 4]\n","[1 5 3 6 0 7 2 4]\n","[1 4 3 6 7 2 0 5]\n","[1 4 7 0 2 5 6 3]\n","[1 4 5 7 2 3 6 0]\n","[7 6 1 3 4 2 5 0]\n","[7 1 5 2 0 6 4 3]\n","[1 3 2 4 7 5 0 6]\n","[1 2 7 4 0 3 5 6]\n","[7 3 1 5 2 4 6 0]\n","[7 5 1 3 6 4 0 2]\n","[1 4 7 3 0 6 2 5]\n","[6 1 5 2 4 7 0 3]\n","[6 7 1 5 0 3 2 4]\n","[3 5 1 7 0 6 4 2]\n","[1 7 5 2 3 6 0 4]\n","[2 1 7 6 4 5 0 3]\n","[1 7 4 3 6 2 0 5]\n","[2 1 3 0 5 4 7 6]\n","[7 1 0 2 4 3 6 5]\n","[1 7 5 2 6 4 0 3]\n","[4 2 1 5 7 6 3 0]\n","[2 7 1 4 5 6 3 0]\n","[5 1 4 6 3 2 0 7]\n","[1 3 6 7 0 4 2 5]\n","[4 2 1 0 3 6 5 7]\n","[7 1 3 5 2 6 0 4]\n","[1 3 4 5 6 0 7 2]\n","[1 0 7 3 5 4 2 6]\n","[1 4 7 2 0 6 3 5]\n","[1 2 4 7 5 6 3 0]\n","[5 1 7 0 4 3 6 2]\n","[5 1 7 6 2 3 0 4]\n","[3 7 1 0 4 2 6 5]\n","[7 5 1 6 3 2 0 4]\n","[1 7 2 0 4 6 3 5]\n","[1 7 2 5 3 0 4 6]\n","[5 1 3 4 2 6 7 0]\n","[1 7 6 5 0 3 4 2]\n","[5 4 2 6 3 1 0 7]\n","[7 1 5 3 2 6 0 4]\n","[1 3 7 5 0 6 4 2]\n","[1 0 4 7 5 2 6 3]\n","[5 1 7 3 4 2 0 6]\n","[5 2 4 0 6 3 7 1]\n","[7 1 0 4 5 6 3 2]\n","[2 5 1 4 3 0 7 6]\n","[3 5 1 7 6 0 4 2]\n","[7 1 4 2 0 6 3 5]\n","[7 2 4 1 3 5 6 0]\n","[1 3 2 5 7 6 0 4]\n","[1 3 5 2 7 0 6 4]\n","[7 1 4 0 2 6 3 5]\n","[1 7 0 3 2 4 5 6]\n","[5 1 7 0 3 4 6 2]\n","[4 7 2 1 5 3 6 0]\n","[1 7 6 3 2 5 4 0]\n","[2 1 5 3 7 6 4 0]\n","[7 0 3 4 5 1 6 2]\n","[7 5 2 6 3 4 1 0]\n","[1 3 5 4 0 6 2 7]\n","[5 1 3 6 0 4 7 2]\n","[0 1 7 6 4 3 2 5]\n","[2 1 7 4 6 5 0 3]\n","[1 3 0 6 7 2 4 5]\n","[1 3 5 7 2 4 6 0]\n","[2 1 7 4 6 5 0 3]\n","[1 3 0 5 4 7 2 6]\n","[7 2 1 4 5 6 0 3]\n","[6 5 4 2 7 1 3 0]\n","[7 1 2 4 0 6 3 5]\n","[3 0 7 6 5 4 2 1]\n","[7 3 1 2 0 5 4 6]\n","[7 1 5 3 6 2 0 4]\n","[4 1 0 2 7 6 3 5]\n","[5 1 2 3 4 7 6 0]\n","[4 6 1 0 2 5 7 3]\n","[7 1 5 0 3 2 6 4]\n","[4 1 5 2 3 0 6 7]\n","[4 1 3 6 5 0 7 2]\n","[5 1 7 3 2 6 0 4]\n","[1 3 6 5 0 4 7 2]\n","[1 5 3 6 4 2 7 0]\n","[1 3 2 6 7 5 0 4]\n","[7 1 6 3 5 0 4 2]\n","[1 7 5 6 3 0 2 4]\n","[7 5 1 0 4 2 6 3]\n","[2 1 7 4 0 6 5 3]\n","[1 7 6 3 4 0 2 5]\n","[3 1 7 5 0 6 2 4]\n","[2 5 0 7 6 4 1 3]\n","[2 1 7 5 4 6 0 3]\n","[1 2 7 4 5 6 0 3]\n","[0 5 3 1 6 2 7 4]\n","[7 2 1 4 0 6 5 3]\n","[4 2 3 0 6 1 7 5]\n","[1 2 7 4 0 5 3 6]\n","[1 3 5 4 2 6 0 7]\n","[1 5 7 4 2 0 6 3]\n","[1 6 2 7 3 4 5 0]\n","[4 5 2 7 3 0 1 6]\n","[7 2 1 5 4 6 3 0]\n","[2 7 1 0 4 6 5 3]\n","[1 5 7 3 2 6 0 4]\n","[1 5 3 6 4 0 2 7]\n","[1 7 0 3 4 6 5 2]\n","[3 1 5 2 7 6 0 4]\n","[0 7 6 3 1 4 2 5]\n","[1 2 5 7 3 0 6 4]\n","[1 7 0 3 4 2 6 5]\n","[3 1 5 0 6 4 7 2]\n","[3 1 5 7 6 2 4 0]\n","[1 3 5 7 0 2 6 4]\n","[7 5 1 2 3 4 0 6]\n","[3 0 4 7 1 2 6 5]\n","[4, 4, 5, 2, 2, 5, 5, 1, 4, 3, 3, 2, 2, 6, 5, 3, 2, 0, 3, 2, 3, 4, 2, 5, 5, 0, 3, 3, 0, 6, 2, 2, 5, 2, 0, 6, 4, 3, 5, 3, 6, 3, 0, 3, 7, 5, 7, 4, 2, 4, 3, 0, 2, 4, 5, 2, 5, 0, 0, 4, 2, 0, 0, 3, 3, 4, 2, 5, 2, 5, 3, 4, 6, 5, 6, 6, 0, 2, 7, 4, 0, 7, 7, 5, 3, 5, 0, 3, 7, 3, 6, 5, 0, 6, 4, 5, 7, 5, 2, 2, 5, 4, 2, 0, 5, 2, 4, 2, 5, 5, 6, 4, 3, 6, 2, 3, 2, 6, 6, 3, 0, 6, 0, 3, 0, 7, 2, 0, 2, 4, 2, 2, 4, 6, 6, 0]\n","[6, 4, 2, 0, 2, 5, 5, 1, 4, 0, 4, 0, 4, 4, 5, 3, 2, 0, 3, 2, 3, 4, 4, 5, 3, 0, 0, 3, 6, 6, 0, 2, 5, 3, 4, 2, 4, 3, 5, 6, 5, 3, 0, 0, 7, 5, 7, 4, 2, 6, 5, 0, 2, 4, 5, 4, 5, 6, 0, 2, 7, 4, 2, 3, 6, 1, 2, 6, 2, 5, 0, 4, 4, 5, 6, 2, 0, 0, 0, 2, 0, 7, 2, 5, 3, 5, 0, 3, 6, 3, 0, 5, 1, 6, 4, 5, 0, 3, 4, 7, 2, 4, 2, 0, 4, 2, 4, 3, 3, 5, 4, 3, 3, 3, 4, 3, 5, 6, 7, 3, 0, 6, 0, 3, 4, 7, 2, 4, 5, 4, 5, 2, 0, 4, 6, 5]\n","0.5514705882352942\n","0.5514705882352942\n","[[11  0  4  4  1  0  1  2]\n"," [ 1  1  0  0  1  0  0  0]\n"," [ 1  0 12  0  2  2  2  1]\n"," [ 0  0  2 14  1  3  1  0]\n"," [ 4  0  5  1 11  1  4  0]\n"," [ 1  0  3  1  0 16  1  0]\n"," [ 2  0  0  2  2  1  6  1]\n"," [ 0  0  2  0  0  0  1  4]]\n"]}]},{"cell_type":"markdown","source":["### 実データで予測"],"metadata":{"id":"82HIBijblrRv"}},{"cell_type":"code","source":["#フォルダをクラス名にする\n","path = \"image\"\n","folders = os.listdir(path)\n","\n","#フォルダ名を抽出\n","classes = [f for f in folders if os.path.isdir(os.path.join(path, f))]\n","n_classes = len(classes)\n","\n","#画像とラベルの格納\n","X_pred = []\n","Y_pred = []\n","\n","#画像を読み込みリサイズする\n","for label,class_name in enumerate(classes):\n","  files = glob.glob(path + \"/\" +  class_name + \"/*.png\")\n","  for file in files:\n","    img = cv2.imread(file)\n","    img = cv2.resize(img,dsize=(64,64))\n","    X_pred.append(img)\n","    Y_pred.append(label)\n","\n","#精度を上げるために正規化\n","X_pred = np.array(X_pred)\n","X_pred = X_pred.astype('float32')\n","X_pred /= 255.0\n","\n","#ラベルの変換\n","\n","Y_pred = np.array(Y_pred)\n","Y_pred = np_utils.to_categorical(Y_pred,n_classes)\n","Y_pred[:5]\n","\n","#学習データとテストデータに分ける(テストデータ2割、学習データ8割)\n","X_train1,X_test1,Y_train1,Y_test1 = train_test_split(X_pred,Y_pred,test_size=0.2)\n","#学習データ(8割)\n","print(X_train1.shape)\n","#テストデータ(2割)\n","print(X_test1.shape)\n","#学習データ(8割)\n","print(Y_train1.shape)\n","#テストデータ(2割)\n","print(Y_test1.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"hU3fOG0Mkut1","executionInfo":{"status":"error","timestamp":1674545235614,"user_tz":-540,"elapsed":546,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"942ae2c6-7ec1-4665-9e53-495903648c27"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-d73fafc92758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#フォルダをクラス名にする\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#フォルダ名を抽出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["model = load_model('cnn_open_400.h5')\n","# classes = pickle.load(open('classes.sav', 'rb'))\n","\n","data = model.predict(X_test1)\n","print()\n","a = []\n","b = []\n","for i in data:\n","  a.append(np.argmax(i))\n","for j in Y_test1:\n","  b.append(np.argmax(j))\n","print(a)\n","print(b)\n","a = np.array(a)\n","b = np.array(b)\n","c = a == b\n","count = 0\n","for k in c:\n","  if k == True:\n","    count+=1\n","print(count/len(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kcvwdg0vl2zK","executionInfo":{"status":"ok","timestamp":1673794112099,"user_tz":-540,"elapsed":3317,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"4e9e30a5-0ec4-4dec-a722-a3aa7e074572"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 73ms/step\n","[3, 3, 6, 4, 7, 4, 2, 3, 3, 6, 3, 5, 6, 7, 2, 7, 4, 6, 6, 3, 6]\n","[3, 1, 0, 5, 6, 0, 7, 3, 5, 4, 2, 2, 6, 3, 6, 2, 1, 7, 7, 6, 0]\n","0.14285714285714285\n"]}]},{"cell_type":"code","source":["model = load_model('cnn_200.h5')\n","# classes = pickle.load(open('classes.sav', 'rb'))\n","\n","data = model.predict(X_test)\n","a = []\n","b = []\n","for i in data:\n","  a.append(np.argmax(i))\n","for j in Y_test:\n","  b.append(np.argmax(j))\n","print(a)\n","print(b)\n","a = np.array(a)\n","b = np.array(b)\n","c = a == b\n","count = 0\n","for k in c:\n","  if k == True:\n","    count+=1\n","print(count/len(c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"id":"iOalTpmyrkDe","executionInfo":{"status":"error","timestamp":1674545363718,"user_tz":-540,"elapsed":15,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"06e08337-49b1-40d2-ca7d-b5628f603e30"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-d8f4ef341316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_open_400.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# classes = pickle.load(open('classes.sav', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import glob as glob\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","from keras.models import load_model\n","import pickle\n","\n","\n","model = load_model('cnn_200.h5')\n","img = cv2.imread(\"./output/myrecording101.png\")\n","img = cv2.resize(img,dsize=(64,64))\n","img = img.astype('float32')\n","img /= 255.0\n","img = img[None, ...]\n","\n","result = model.predict(img)\n","result = np.array(result)\n","\n","np.argmax(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6D8xFIFjnxA","executionInfo":{"status":"ok","timestamp":1673792287544,"user_tz":-540,"elapsed":13567,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"16bac900-e4ba-48a3-e292-d4cdea5572f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 7s 7s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["!pip install sounddevice"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFk2nDcagyDd","executionInfo":{"status":"ok","timestamp":1673955337389,"user_tz":-540,"elapsed":4995,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"f898e299-01a4-418f-82a7-2e5658ce26c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sounddevice\n","  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.8/dist-packages (from sounddevice) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from CFFI>=1.0->sounddevice) (2.21)\n","Installing collected packages: sounddevice\n","Successfully installed sounddevice-0.4.5\n"]}]},{"cell_type":"code","source":["import sounddevice as sd\n","import soundfile as sf\n","import numpy as np\n","import librosa as lb\n","import librosa.display\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","def voice_input():\n","   \n","    duration = 3  # 3秒間録音する\n","    # i = i+100\n","\n","    # デバイス情報関連\n","    sd.default.device = [1, 3] # Input, Outputデバイス指定\n","    input_device_info = sd.query_devices(device=sd.default.device[1])\n","    sr_in = int(input_device_info[\"default_samplerate\"])\n","\n","    # 録音\n","    myrecording = sd.rec(int(duration * sr_in), samplerate=sr_in, channels=2)\n","    sd.wait() # 録音終了待ち\n","\n","    print(myrecording.shape) #=> (duration * sr_in, channels)\n","\n","    # 録音信号のNumPy配列をwav形式で保存\n","    sf.write(\"G:/マイドライブ/Google Colab/wav/myrecording.wav\", myrecording, sr_in)\n","  \n","def png_trans():\n","  y,sr = lb.load(f'G:/マイドライブ/Google Colab/wav/myrecording.wav') # 音声読み込み\n","  S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, win_length=512, hop_length=512) # メルスペクトログラムに変換\n","  S_dB = librosa.power_to_db(S, ref=np.max)\n","\n","  # プロット\n","  img = librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='linear') #yの値はlinearにしないとおかしくなった\n","  # filename = filename.replace('.wav','')\n","  # filename = filename.replace('C:/Users/20t311/Documents/大学関連/実験2/myvoice/angry/','')\n","  # filename = f'{filename}'\n","\n","  plt.savefig(\"G:/マイドライブ/Google Colab/output/myrecording301.png\", format=\"png\", dpi=300)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"230Qqp4Qgfh-","executionInfo":{"status":"error","timestamp":1673955344059,"user_tz":-540,"elapsed":11,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"36fc366e-1ddc-4744-ed88-ee3d36155e19"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-38b783899a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msounddevice\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PortAudio library not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0m_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_libname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: PortAudio library not found"]}]},{"cell_type":"code","source":["img = cv2.imread(\"output/myrecording0.png\")\n","print(img)\n","img = cv2.resize(img,dsize=(64,64))\n","img = img.astype('float32')\n","img /= 255.0\n","img = img[None, ...]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLNnmlArl-yy","executionInfo":{"status":"ok","timestamp":1673957263285,"user_tz":-540,"elapsed":1156,"user":{"displayName":"Mayuna TAKANO","userId":"11012886210599922156"}},"outputId":"900d0f0f-0902-44d3-9c45-5448dcfd2bd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," ...\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]\n","\n"," [[255 255 255]\n","  [255 255 255]\n","  [255 255 255]\n","  ...\n","  [255 255 255]\n","  [255 255 255]\n","  [255 255 255]]]\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyND/AlT2smMylUIDOP/uhtQ"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"3e87aa7f53a25cfb2ef6b0ed3ac990eedff0c5a2d4f7b16a76388575c29c50b5"}}},"nbformat":4,"nbformat_minor":0}